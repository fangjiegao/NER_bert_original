python3 ner_classifier.py \
  --task_name=ner_pd \
  --do_train=false \
  --do_eval=false \
  --vocab_file=/home/gaofangjie/bert-checkpoint/chinese_L-12_H-768_A-12/vocab.txt \
  --bert_config_file=/home/gaofangjie/bert-checkpoint/chinese_L-12_H-768_A-12/bert_config.json \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=5e-5 \
  --num_train_epochs=3.0 \
  --output_dir=/home/gaofangjie/nlp_model
  --init_checkpoint=/home/gaofangjie/bert-checkpoint/chinese_L-12_H-768_A-12/bert_model.ckpt \


nohup python3 ner_classifier.py   --task_name=ner_pd   --do_train=false   --do_eval=false   --do_predict=true  --vocab_file=/home/gaofangjie/bert-checkpoint/chinese_L-12_H-768_A-12/vocab.txt   --bert_config_file=/home/gaofangjie/bert-checkpoint/chinese_L-12_H-768_A-12/bert_config.json   --max_seq_length=128   --train_batch_size=32   --learning_rate=5e-5   --num_train_epochs=3.0   --output_dir=/home/gaofangjie/nlp_model >> /home/gaofangjie/nlp_model/ner_log_test.log 2>&1&